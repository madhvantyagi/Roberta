{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f8edc-891d-4ab8-8f54-92a7de1501bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets accelerate evaluate bitsandbytes peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd781fc-f5f1-47b1-97b9-3c03bc03341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x150e001724d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Avoid deadlock warning from huggingface/tokenizers\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import bitsandbytes as bnb  # 8-bit ops and optimizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "# Use same seeds, ranks, etc. that you used in your original code\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d139cb55-8874-48f6-8ff3-39db0382a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LoRA config: Adjust to match your exact hyperparams\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query\", \"value\", \"key\", \"output.dense\"]  # typical for attention layers\n",
    ")\n",
    "\n",
    "# Example: bitsandbytes optimizer\n",
    "# (If you used AdamW or something else, keep it the same as your original code)\n",
    "optimizer_class = bnb.optim.Adam8bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "638aafc8-7b4b-4285-bee9-298c305d76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: AG News dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "test_dataset = tokenized_dataset[\"test\"]\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b7250a3-a806-4a93-8e69-19360c821148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 1024)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-23): 24 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_lora_model(lora_model_path: str):\n",
    "    \"\"\"\n",
    "    Loads a LoRA-finetuned RoBERTa model from a specified directory,\n",
    "    along with the tokenizer.\n",
    "    \"\"\"\n",
    "    # Load the PEFT config to identify the base model\n",
    "    peft_config = PeftConfig.from_pretrained(lora_model_path)\n",
    "    \n",
    "    # Load the base model\n",
    "    base_model = RobertaForSequenceClassification.from_pretrained(\n",
    "        peft_config.base_model_name_or_path,\n",
    "        num_labels=4  # for AGNews\n",
    "    )\n",
    "    # Attach LoRA adapters\n",
    "    model = PeftModel.from_pretrained(base_model, lora_model_path)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load tokenizer from the same folder\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(lora_model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "lora_model_path = \"./finetuned_roberta_large_lora\"  # adjust to your path\n",
    "teacher_model, teacher_tokenizer = load_lora_model(lora_model_path)\n",
    "\n",
    "teacher_model.eval()  # teacher in eval mode\n",
    "teacher_model.cuda()  # or .to(device) if using HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57d8f75-d336-40e2-b2c3-ba0bb548400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=4\n",
    ")\n",
    "# Add LoRA\n",
    "student_model = get_peft_model(student_model, lora_config)\n",
    "\n",
    "# Freeze all base RoBERTa weights so only LoRA is trainable\n",
    "for name, param in student_model.named_parameters():\n",
    "    if \"lora_\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "student_model.cuda()  # HPC GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "735ce50d-26b8-41b3-a499-e9bbf6cab375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable student parameters (LoRA): 958464\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable student parameters (LoRA): {trainable_params}\")\n",
    "# Make sure this is <= 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4adb348-54c3-4e61-99ca-d8ac43b1fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, teacher, alpha_distill=0.5, temperature=2.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.teacher = teacher\n",
    "        self.alpha_distill = alpha_distill\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\", None)\n",
    "        \n",
    "        # Student forward\n",
    "        outputs_student = model(**inputs)\n",
    "        student_logits = outputs_student.logits\n",
    "        \n",
    "        # Standard CE loss\n",
    "        import torch.nn.functional as F\n",
    "        ce_loss = F.cross_entropy(student_logits, labels)\n",
    "        \n",
    "        # Teacher forward (no grad)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = self.teacher(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"]\n",
    "            )\n",
    "            teacher_logits = outputs_teacher.logits\n",
    "        \n",
    "        # Distillation loss (KL div)\n",
    "        student_log_probs = F.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "        teacher_probs = F.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "        distill_loss = F.kl_div(\n",
    "            student_log_probs, \n",
    "            teacher_probs, \n",
    "            reduction=\"batchmean\"\n",
    "        ) * (self.temperature ** 2)\n",
    "        \n",
    "        # Combine them\n",
    "        loss = (1 - self.alpha_distill) * ce_loss + self.alpha_distill * distill_loss\n",
    "\n",
    "        return (loss, outputs_student) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265441ae-8126-4901-9b26-f90ec336d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilled_roberta_lora\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    # If your older Transformers doesn’t support \"evaluation_strategy\", remove it or upgrade\n",
    "    fp16=True,  # HPC often has half-precision\n",
    "    report_to=\"none\",\n",
    "    label_names=[\"labels\"]  # fixes \"No label_names provided\" warning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af999e23-a91d-439a-9151-9fcefa27e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6238/2431091360.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DistillationTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    teacher=teacher_model,\n",
    "    alpha_distill=0.5,      # weight for teacher’s KL loss\n",
    "    temperature=2.0,        # distillation temperature\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,       # if you used trainer's auto padding\n",
    "    # data_collator=your_data_collator,\n",
    "    optimizers=(None, None)    # or set your bitsandbytes optimizer here if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc4c3634-c6b1-4bfd-98f8-09222eccd8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11274' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11274/18750 51:32 < 34:11, 3.64 it/s, Epoch 3.01/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.209213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.194493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.190322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, eval_metrics)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py:3736\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3736\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3738\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3741\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3742\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m, in \u001b[0;36mDistillationTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Teacher forward (no grad)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     outputs_teacher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteacher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     teacher_logits \u001b[38;5;241m=\u001b[39m outputs_teacher\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Distillation loss (KL div)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/peft/peft_model.py:1559\u001b[0m, in \u001b[0;36mPeftModelForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1558\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1570\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/peft/tuners/tuners_utils.py:193\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1322\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1322\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1333\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1334\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:978\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    976\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 978\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    991\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    622\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         output_attentions,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:325\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    314\u001b[0m         hidden_states,\n\u001b[1;32m    315\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m         output_attentions,\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    323\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 325\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_for_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:182\u001b[0m, in \u001b[0;36mRobertaSelfAttention.transpose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    180\u001b[0m new_x_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[1;32m    181\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(new_x_shape)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "eval_metrics = trainer.evaluate()\n",
    "print(\"Eval metrics:\", eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aab15016-8254-49f4-b480-143e47e468d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset[\"train\"].features[\"label\"].names\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    output = model(**inputs)\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47c9be6f-c8db-4ff8-903d-cedaf17ae7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class: 1, Label: Sports, Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\n",
      "\n",
      " Class: 2, Label: Business, Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindlinand of ultra-cynics, are seeing green again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify( student_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
    "classify( student_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d95927-7508-4a14-93cc-aeaf000e0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        inference_model: The model to evaluate.\n",
    "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
    "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
    "                         If False, only predictions will be returned.\n",
    "        batch_size (int): Batch size for inference.\n",
    "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True, returns a tuple (metrics, predictions)\n",
    "        If labelled is False, returns the predictions.\n",
    "    \"\"\"\n",
    "    # Create the DataLoader\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    if labelled:\n",
    "        metric = evaluate.load('accuracy')\n",
    "\n",
    "    # Loop over the DataLoader\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        # Move each tensor in the batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            # Expecting that labels are provided under the \"labels\" key.\n",
    "            references = batch[\"labels\"]\n",
    "            metric.add_batch(\n",
    "                predictions=predictions.cpu().numpy(),\n",
    "                references=references.cpu().numpy()\n",
    "            )\n",
    "\n",
    "    # Concatenate predictions from all batches\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        eval_metric = metric.compute()\n",
    "        print(\"Evaluation Metric:\", eval_metric)\n",
    "        return eval_metric, all_predictions\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "205323ae-3bc0-4c53-b13b-7c322964d5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 950/950 [00:22<00:00, 41.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metric: {'accuracy': 0.9377631578947369}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Suppose you have a tokenizer already defined:\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "# Check evaluation accuracy\n",
    "_, _ = evaluate_model(student_model, test_dataset, True, 8, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92f423da-5827-439c-8446-643f01e2af29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>true_label_name</th>\n",
       "      <th>predicted_label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Some People Not Eligible to Get in on Google I...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Live: Olympics day four Richard Faulds and Ste...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intel to delay product aimed for high-definiti...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yahoo! Ups Ante for Small Businesses Web giant...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices bubble to record high The price of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>World</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  true_label  \\\n",
       "0  Some People Not Eligible to Get in on Google I...           3   \n",
       "1  Live: Olympics day four Richard Faulds and Ste...           0   \n",
       "2  Intel to delay product aimed for high-definiti...           2   \n",
       "3  Yahoo! Ups Ante for Small Businesses Web giant...           2   \n",
       "4  Oil prices bubble to record high The price of ...           0   \n",
       "\n",
       "   predicted_label true_label_name predicted_label_name  \n",
       "0                2        Sci/Tech             Business  \n",
       "1                1           World               Sports  \n",
       "2                3        Business             Sci/Tech  \n",
       "3                3        Business             Sci/Tech  \n",
       "4                2           World             Business  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "device='cuda'  \n",
    "wrong_predictions = []\n",
    "\n",
    "# Create dataloader\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
    "student_model.eval()\n",
    "student_model.to('cuda')\n",
    "\n",
    "# Collect wrong predictions\n",
    "for batch in eval_dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = student_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = outputs.logits.argmax(dim=-1)\n",
    "    \n",
    "    for j in range(len(labels)):\n",
    "        if preds[j] != labels[j]:\n",
    "            wrong_predictions.append({\n",
    "                \"text\": tokenizer.decode(input_ids[j], skip_special_tokens=True),\n",
    "                \"true_label\": labels[j].item(),\n",
    "                \"predicted_label\": preds[j].item()\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "wrong_df = pd.DataFrame(wrong_predictions)\n",
    "if id2label:\n",
    "    wrong_df[\"true_label_name\"] = wrong_df[\"true_label\"].map(id2label)\n",
    "    wrong_df[\"predicted_label_name\"] = wrong_df[\"predicted_label\"].map(id2label)\n",
    "\n",
    "wrong_df.to_csv(\"wrong_predictions.csv\", index=False)\n",
    "wrong_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cc5029d-7f9c-4428-8e32-c6dc9dae2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8000/8000 [00:02<00:00, 3464.73 examples/s]\n",
      "100%|██████████| 1000/1000 [00:25<00:00, 39.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to inference_output.csv\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"results\"\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
    "    return tokenized\n",
    "\n",
    "#Load your unlabelled data\n",
    "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset\n",
    "\n",
    "# Run inference and save predictions\n",
    "preds = evaluate_model(student_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy()  # or preds.tolist()\n",
    "})\n",
    "df_output.to_csv(os.path.join(output_dir,\"inference_output.csv\"), index=False)\n",
    "print(\"Inference complete. Predictions saved to inference_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ee9f1c4-f2ab-4e4e-a95e-025ff2ee7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f07a5283-a942-463e-8693-800b0d9ff4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, dataset, tokenizer, batch_size=64):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    student_model.eval().to(device)\n",
    "\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    \n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3595e928-5bd6-49c5-a26b-e66a1ae8e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(student_model, test_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ee458e0-85b2-47ae-ba92-7463c84bec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8000/8000 [00:02<00:00, 3415.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load your unlabelled data\n",
    "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "424a2cd3-9964-4012-9dba-bf81df0ecd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to inference_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference and save predictions\n",
    "preds = evaluate_model(student_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy()  # or preds.tolist()\n",
    "})\n",
    "df_output.to_csv(os.path.join(output_dir,\"inference_output.csv\"), index=False)\n",
    "print(\"Inference complete. Predictions saved to inference_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1286edb0-fdb8-4cce-898d-259ef10f456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/ns6287/finetuned_roberta_large_lora.zip'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip the folder (this creates finetuned_roberta_large_lora.zip in your current working dir)\n",
    "shutil.make_archive(\"finetuned_roberta_large_lora\", \"zip\", \"finetuned_roberta_large_lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23cccc9-170f-4fc1-afa9-2dafb42c9156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='finetuned_roberta_large_lora.zip' target='_blank'>finetuned_roberta_large_lora.zip</a><br>"
      ],
      "text/plain": [
       "/scratch/ns6287/finetuned_roberta_large_lora.zip"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Show clickable download link\n",
    "FileLink(\"finetuned_roberta_large_lora.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0368c06-b8c3-4f66-a2f1-f3613ab46cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
